{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7nMm8wufypVc9OxPT2gJu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QsFbxV69Lu9r","executionInfo":{"status":"ok","timestamp":1665074732896,"user_tz":-120,"elapsed":2802,"user":{"displayName":"A","userId":"08663750758565944950"}}},"outputs":[],"source":["import torch\n","from torch import nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import csv\n","import pandas as pd\n","from torch.utils.data import DataLoader\n","from matplotlib import pyplot as plt\n","from matplotlib import cm"]},{"cell_type":"code","source":["device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n","num_of_devices = torch.cuda.device_count()\n","print(f' num of devices is {num_of_devices}')\n","if torch.cuda.is_available():\n","  print(f' devive name is {torch.cuda.get_device_name()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTpDfgn_MAya","executionInfo":{"status":"ok","timestamp":1665074737814,"user_tz":-120,"elapsed":7,"user":{"displayName":"A","userId":"08663750758565944950"}},"outputId":"989f61dc-d3f2-4d5a-dcb3-7140d5ef2a7b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[" num of devices is 0\n"]}]},{"cell_type":"code","source":["### generacja danych\n","fun = lambda x, y: 2*np.sin( 2.8*x *y) + 3 * np.sin(2.6*x) + 2 * np.cos(4.1*y)\n","\n","lb = 0\n","ub = 1\n","xx = np.arange(lb, ub, 1e-1)\n","xx, yy = np.meshgrid(xx, xx)\n","\n","# tworzy 100 wartosci funkcji\n","ff = fun(xx, yy)\n","\n","# prosty wykres z wykorzystaniem pyplot\n","fig = plt.figure()\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_surface(xx, yy, ff, cmap=cm.coolwarm)\n","ax.scatter(xx, yy, ff + 0.5 * np.random.randn(*ff.shape))"],"metadata":{"id":"vYKQWstSMC1G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_data(fun, noise_amp, num_of_data):\n","  \n","  mat = np.zeros((num_of_data, 3))\n","  for i in range(num_of_data):\n","    x, y = np.random.randn(2)\n","    # dodaje szum do danych\n","    f = fun(x, y) + noise_amp * np.random.randn()\n","    mat[i, 0] = x\n","    mat[i, 1] = y\n","    mat[i, 2] = f\n","  \n","  return mat"],"metadata":{"id":"NmRwe4V4MGye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate data\n","data_array = generate_data(fun, 0.5, 10000)\n","\n","# export to csv with pandas\n","headers = ['x_value', 'y_value', 'fun_value']\n","\n","with open('/data.csv', 'w') as f:\n","  writer = csv.writer(f)\n","  writer.writerow(headers)\n","  for i in range(data_array.shape[0]):\n","    writer.writerow(data_array[i, :])"],"metadata":{"id":"jx8CDSRfMGvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load data from csv with Pandas\n","df = pd.read_csv('/data.csv')\n","print(type(df))\n","\n","# show header of dataframe\n","df.head()"],"metadata":{"id":"blM0FW_yMGoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get one row\n","data_row = df.iloc(1)\n","print(df.iloc[1])"],"metadata":{"id":"caYBQiRGMGi5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normalizacja \n","arr = np.array(df)\n","print(arr.shape)\n","data_mu = np.mean(arr, axis=0)\n","data_std = np.std(arr, axis=0)\n","print(f'dama mu is : {data_mu} data std is {data_std}')"],"metadata":{"id":"KxgWaPhOMGgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### normalizing\n","arr = arr - data_mu\n","print(np.mean(arr, axis=0))\n","print(f'shape of data is  : {arr.shape}')\n","data_ar = (arr - data_mu) / (data_std**2)\n","print(data_ar is None)"],"metadata":{"id":"r_m8LoBNMGdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create custom dataloader\n","from torch.utils.data import Dataset\n","\n","class MyDataloader(Dataset):\n","  def __init__(self, csv_file, transform=True):\n","    super().__init__()\n","\n","    self.data_df = pd.read_csv(csv_file)\n","    self.data_array = np.array(self.data_df)\n","    self.transform = transform\n","    self.data_std = np.mean(self.data_array, axis=0)\n","    self.data_mu = np.mean(self.data_array, axis=0)\n","\n","\n","\n","  def __len__(self):\n","    return len(self.data_df)\n","\n","  def __getitem__(self, index):\n","    \n","    # normalize function value to [0, 1] intervale\n","    if self.transform:\n","      self.data_array[:, -1] = (self.data_array[:, -1] - np.min(self.data_array[:, -1])) \\\n","       / (np.max(self.data_array[:, -1]) - np.min(self.data_array[:, -1]))\n","\n","    return (torch.tensor(self.data_array[index, 0:-1], dtype=torch.float32).to(device),\n","            torch.tensor(self.data_array[index, -1], dtype=torch.float32).to(device))"],"metadata":{"id":"NnAb4X4_MWVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create DL\n","dataset = MyDataloader('/data.csv', )"],"metadata":{"id":"AU0ijd27MWR5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(next(iter(dataset)))\n","print(len(dataset))"],"metadata":{"id":"cIV9gYUSMWPK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set, test_set = torch.utils.data.random_split(dataset,\n","                                                    [int(0.7 * len(dataset)), int(0.3 * len(dataset))])"],"metadata":{"id":"Vb_kToSBMWL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'lenght of tarinset is {len(train_set)}')\n","print(next(iter(train_set)))"],"metadata":{"id":"Bg8XHc2TMWEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(dataset=train_set, batch_size = 10, shuffle=True)\n","test_loader = DataLoader(dataset=test_set, batch_size = 10, shuffle=True)"],"metadata":{"id":"xz6O0xwgMWCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader_output = next(iter(train_loader))\n","print(f'outpot of data loader {loader_output}')\n","print(f'shape of output of data loader {loader_output[0].shape}')\n","print(len(loader_output))"],"metadata":{"id":"UZY0jpRdMV_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Regresor(nn.Module):\n","  def __init__(self, input_features):\n","    super().__init__()\n","\n","    self.first_layer = nn.Linear(in_features=input_features, out_features=128)\n","    self.second_layer = nn.Linear(in_features=128, out_features=128)\n","    \n","    self.mid1 =  nn.Linear(in_features=128, out_features=128)\n","    self.mid2 = nn.Linear(in_features=128, out_features=128)\n","\n","    self.last_layer = nn.Linear(in_features=128, out_features=1)\n","    # self.regularization_layer = nn.Dropout(p=0.5)\n","    self.activate = F.relu\n","    self.loss = F.mse_loss\n","\n","    # regularization layer\n","    self.reg_drop = nn.Dropout(p=0.5)\n","\n","  def forward(self, x):\n","    x = self.first_layer(x)\n","    x = self.activate(x)\n","\n","    # x = self.regularization_layer(x)\n","    x = self.second_layer(x)\n","    x = self.activate(x)\n","    # regularizer\n","    x = self.reg_drop(x)\n","    x = self.mid1(x)\n","    x = self.activate(x)\n","    # regularizer\n","    x = self.reg_drop(x)\n","    x = self.mid2(x)\n","    x = self.activate(x)\n","    \n","    return self.last_layer(x)"],"metadata":{"id":"m4ze84THMV8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tworze model\n","model = Regresor(input_features=2)\n","# device = 'cuda:0'\n","# sent model to cuda\n","if torch.cuda.is_available():\n","  torch.cuda.set_device(device)\n","  model.cuda()\n","\n","\n","# test of forward pass\n","data_batch, targets_batch = next(iter(train_loader))\n","data_batch = data_batch.to(device)\n","targets_batch = targets_batch.to(device)\n","print(data_batch.device)\n","print(targets_batch.device)\n","\n","print(f' shape of input {data_batch.shape}')\n","y = model(data_batch)\n","print(f'data_batch is {data_batch}')\n","print(f'shape of output {y.shape} the type is {type(y)} and values are: {y}')"],"metadata":{"id":"pb2cmBrTMV5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check on test set\n","def test_model(trained_model, is_regularize, test_loader):\n","  trained_model.eval()\n","  test_related_error = []\n","  test_losses = []\n","  \n","  with torch.no_grad():\n","    for batch_ind, (data, targets) in enumerate(test_loader):\n","\n","      if torch.cuda.is_available():\n","        data = data.to(device)\n","        targets = targets.to(device)\n","      \n","      y = torch.squeeze(trained_model(data))\n","      \n","      if is_regularize:\n","        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","        loss = model.loss(predictions, targets) + l2_lambda * l2_norm\n","      \n","      else:\n","        loss = trained_model.loss(y, targets)\n","\n","      ls = loss.item()\n","      test_losses.append(ls)\n","\n","      test_related_error.append(torch.mean((targets - y) / targets).cpu())\n","    \n","    tre = torch.tensor(np.array(test_related_error))\n","    test_loss = torch.mean(torch.tensor(np.array(test_losses)))\n","    \n","    return test_loss, torch.mean(tre)"],"metadata":{"id":"bnTuIcIEMseU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training loop\n","from tqdm import tqdm\n","num_of_epochs = 30\n","reg = False\n","l2_lambda = 0.001\n","lr = 0.00005\n","\n","model = Regresor(input_features=2)\n","\n","# sent model to device\n","if torch.cuda.is_available():\n","  model.cuda()\n","\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n","\n","test_relative_error = []\n","train_losses = []\n","test_losses = []\n","\n","\n","for epoch in tqdm(range(num_of_epochs), desc='training progress'):\n","\n","  # set train mode\n","  model.train()\n","\n","  epoch_losses = []\n","  for batch_index, (data, targets) in enumerate(train_loader):\n","    # if torch.cuda.is_available():\n","    data = data.to(device)\n","    targets = targets.to(device)\n","\n","    # forward\n","    ### tzreba squeeze by miec te same wymiary 'target' oraz 'predict' inaczej 'loss' liczy sie zle!!\n","    predictions = torch.squeeze(model(data))\n","    if reg:\n","      l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","      loss = model.loss(predictions, targets) + l2_lambda * l2_norm\n","    \n","    else:\n","      loss = model.loss(predictions, targets)\n","\n","\n","    epoch_losses.append(loss.item()) \n","    # losses.append()\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  \n","  #### and of epoch ###\n","\n","  # perform test after training epoch\n","  test_loss, test_rel_error = test_model(model,\n","                                             is_regularize=reg,\n","                                             test_loader=test_loader\n","                                             )\n","\n","  ## save training loss\n","  averaged_loss = np.mean(epoch_losses)\n","  train_losses.append(averaged_loss)\n","  test_losses.append(test_loss)\n","  test_relative_error.append(test_rel_error)\n","\n","\n","  # compute average loss\n","  print(f'train loss : {averaged_loss}; test loss : {test_loss}')"],"metadata":{"id":"BO5IWZabMsbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print training loss\n","\n","x = np.arange(0, len(train_losses))\n","plt.plot(x, train_losses, label='train loss')\n","plt.plot(x, test_losses, label='test loss')\n","plt.legend()\n","plt.grid()\n","plt.title(f'MSE-loss - L2 -regularisation is {reg}')"],"metadata":{"id":"gZYp5bN6MsYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jx9g71SoMsVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R4tT0jasMsRV"},"execution_count":null,"outputs":[]}]}